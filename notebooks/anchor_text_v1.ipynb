{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import base64\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import codecs\n",
    "import json\n",
    "from itertools import groupby\n",
    "import difflib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_filepath = '/Users/kd/Workspace/python/DOCX/document-formatting/data/input/Archive1.docx'\n",
    "output_dir     = '/Users/kd/Workspace/python/DOCX/document-formatting/data/output'\n",
    "\n",
    "fetch_content_filepath = '/Users/kd/Workspace/python/DOCX/document-formatting/data/input/long_paragraph.json'\n",
    "filename       = os.path.splitext(os.path.basename(input_filepath))[0]\n",
    "translated_filename = filename + '_translated' + '.docx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_xmltree(xml):\n",
    "    return etree.tostring(xml)\n",
    "\n",
    "def get_xml_tree(xml_string):\n",
    "    return etree.fromstring(xml_string)\n",
    "\n",
    "def get_xmltree(filepath, parse='xml'):\n",
    "    if parse == 'html':\n",
    "        parser = etree.HTMLParser()\n",
    "        tree   = etree.parse(open(filepath, mode='r', encoding='utf-8'), parser)\n",
    "        return tree\n",
    "    else:\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        with open(filepath,'r') as file:\n",
    "            xml_string    = file.read()\n",
    "            return etree.fromstring(bytes(xml_string, encoding='utf-8'), parser)\n",
    "    return None\n",
    "\n",
    "def check_element_is(element, type_char):\n",
    "    word_schema1 = \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"\n",
    "    word_schema2 = 'http://purl.oclc.org/ooxml/wordprocessingml/main'\n",
    "     \n",
    "    return (element.tag == '{%s}%s' % (word_schema1, type_char)) or (element.tag == '{%s}%s' % (word_schema2, type_char))\n",
    "\n",
    "def get_specific_tags(node, type_char):\n",
    "    nodes = []\n",
    "    for elem in node.iter():\n",
    "        if check_element_is(elem, type_char):\n",
    "            nodes.append(elem)\n",
    "    return nodes\n",
    "\n",
    "def add_identifier(node):\n",
    "    node.attrib['id'] = str(uuid.uuid4())\n",
    "\n",
    "def is_run_superscript(run):\n",
    "    attrib    = {}\n",
    "    vertAlign = get_specific_tags(run, 'vertAlign')\n",
    "    if len(vertAlign) > 0:\n",
    "        for key in vertAlign[0].attrib.keys():\n",
    "            attrib['vertAlign_' + key.split('}')[-1]] = vertAlign[0].attrib[key]\n",
    "    if 'vertAlign_val' in attrib:\n",
    "        if attrib['vertAlign_val'] == 'superscript':\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def update_run_text(r1, r2):\n",
    "    t1s = get_specific_tags(r1, 't')\n",
    "    t2s = get_specific_tags(r2, 't')\n",
    "#     print('r1 text [%s], r2 text [%s]'% (t1s[0].text, t2s[0].text))\n",
    "    t1s[0].text = t1s[0].text + t2s[0].text\n",
    "    t2s[0].text = ''\n",
    "    \n",
    "def get_run_properties(run):\n",
    "    attrib = {}\n",
    "    rFonts = get_specific_tags(run, 'rFonts')\n",
    "    sz     = get_specific_tags(run, 'sz')\n",
    "    szCs   = get_specific_tags(run, 'szCs')\n",
    "    \n",
    "    if len(rFonts) > 0:\n",
    "        for key in rFonts[0].attrib.keys():\n",
    "            attrib['rFonts_' + key.split('}')[-1]] = rFonts[0].attrib[key]\n",
    "    \n",
    "    if len(sz) > 0:\n",
    "        for key in sz[0].attrib.keys():\n",
    "            attrib['sz_' + key.split('}')[-1]] = sz[0].attrib[key]\n",
    "        \n",
    "    if len(szCs) > 0:\n",
    "        for key in szCs[0].attrib.keys():\n",
    "            attrib['szCs_' + key.split('}')[-1]] = szCs[0].attrib[key]\n",
    "\n",
    "    return attrib\n",
    "\n",
    "def update_font_property(p, reduce=4):    \n",
    "    szs    = get_specific_tags(p, 'sz')\n",
    "    szCss  = get_specific_tags(p, 'szCs')\n",
    "    value  = '{%s}%s' % (\"http://schemas.openxmlformats.org/wordprocessingml/2006/main\", 'val')\n",
    "\n",
    "    for szCs in szCss:\n",
    "        size  = szCs.attrib[value]\n",
    "        szCs.set(value, str(int(size) - reduce))\n",
    "\n",
    "    for sz in szs:\n",
    "        size  = sz.attrib[value]\n",
    "        sz.set(value, str(int(size) - reduce))\n",
    "    \n",
    "def compare_run_properties(run1, run2):\n",
    "    attrib1 = get_run_properties(run1)\n",
    "    attrib2 = get_run_properties(run2)\n",
    "    \n",
    "    if all (k in attrib1 for k in ('rFonts_ascii', 'sz_val', 'szCs_val')):\n",
    "        if all (k in attrib2 for k in ('rFonts_ascii', 'sz_val', 'szCs_val')):\n",
    "            if (attrib1['rFonts_ascii'] == attrib2['rFonts_ascii']) and \\\n",
    "            (attrib1['szCs_val'] == attrib2['szCs_val']) and \\\n",
    "            (attrib1['sz_val'] == attrib2['sz_val']) :\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_line_connections(p):\n",
    "    runs             = get_specific_tags(p, 'r')\n",
    "    text_runs        = []\n",
    "    \n",
    "    for run in runs:\n",
    "        if is_run_superscript(run) == False:\n",
    "            text_runs.append(run)\n",
    "\n",
    "    line_connections = []\n",
    "    for index in range(len(text_runs) - 1):\n",
    "        if (compare_run_properties(text_runs[index], text_runs[index+1])):\n",
    "            line_connections.append((index, index+1, 'CONNECTED'))\n",
    "        else:\n",
    "            line_connections.append((index, index+1, 'NOT_CONNECTED'))\n",
    "    return line_connections\n",
    "\n",
    "def arrange_grouped_line_indices(line_connections, debug=False):\n",
    "    lines          = [list(i) for j, i in groupby(line_connections, lambda a: a[2])]\n",
    "    if debug:\n",
    "        print('arrange_grouped_line_indices: %s \\n---------\\n' % (str(lines)))\n",
    "        \n",
    "    arranged_lines = []\n",
    "\n",
    "    for line_items in lines:\n",
    "        indices = []\n",
    "        for line_item in line_items:\n",
    "            indices.append(line_item[0])\n",
    "            indices.append(line_item[1])\n",
    "        indices = sorted(list(set(indices)))\n",
    "        arranged_lines.append([indices, line_items[0][2]])\n",
    "        \n",
    "    if debug:\n",
    "        print('arrange_grouped_line_indices,arranged_lines : %s \\n---------\\n' % (str(arranged_lines)))\n",
    "    \n",
    "    final_arranged_lines = []\n",
    "    \n",
    "    if len(arranged_lines) == 1:\n",
    "        final_arranged_lines.append([arranged_lines[0][0], arranged_lines[0][1]])\n",
    "    else:\n",
    "        for index, line_item in enumerate(arranged_lines):\n",
    "            if index == 0 and line_item[1] == 'NOT_CONNECTED':\n",
    "                del line_item[0][-1]\n",
    "            if index > 0 and index < (len(arranged_lines) - 1) and line_item[1] == 'NOT_CONNECTED':\n",
    "                del line_item[0][0]\n",
    "                del line_item[0][-1]\n",
    "            if index == (len(arranged_lines) - 1) and line_item[1] == 'NOT_CONNECTED':\n",
    "                del line_item[0][0]\n",
    "\n",
    "            final_arranged_lines.append([line_item[0], line_item[1]])\n",
    "    if debug:\n",
    "        print('final_arrange_grouped_line_indices,arranged_lines : %s \\n---------\\n' % (str(final_arranged_lines)))\n",
    "            \n",
    "    return final_arranged_lines\n",
    "\n",
    "def merge_runs(node, grouped_runs, debug=False):\n",
    "    runs      = get_specific_tags(node, 'r')\n",
    "    text_runs = []\n",
    "    \n",
    "    for run in runs:\n",
    "        if is_run_superscript(run) == False:\n",
    "            text_runs.append(run)\n",
    "\n",
    "    for element in grouped_runs:\n",
    "        if (element[1] == 'CONNECTED'):\n",
    "            for index, run_index in enumerate(element[0]):\n",
    "                if (index > 0):\n",
    "                    if (debug):\n",
    "                        print('merge index %d with %d' % ( run_index, 0))\n",
    "                    update_run_text(text_runs[0], text_runs[run_index])\n",
    "                    text_runs[run_index].getparent().remove(text_runs[run_index])\n",
    "                    \n",
    "def update_document_runs(document):\n",
    "    '''\n",
    "    the function iterates through the p tags and merges run that have exactly same\n",
    "    visual property.\n",
    "    '''\n",
    "    tag_name                 = 'p'\n",
    "    tags                     = get_specific_tags(document, tag_name)\n",
    "    for p in tags:\n",
    "        grouped_runs = arrange_grouped_line_indices(get_line_connections(p))\n",
    "        merge_runs(p, grouped_runs, debug=False)\n",
    "    return document\n",
    "\n",
    "def get_text_tags(document):\n",
    "    tags         = []\n",
    "    runs         = get_specific_tags(document, 'r')\n",
    "    for run in runs:\n",
    "        if is_run_superscript(run) == False:\n",
    "            texts = get_specific_tags(run, 't')\n",
    "            for text in texts:\n",
    "                if text.text and len(text.text.strip()) > 0:\n",
    "                    add_identifier(text)\n",
    "                    tags.append(text)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docx(filepath, working_dir):\n",
    "    filename       = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    extract_dir    = os.path.join(working_dir, filename)\n",
    "    \n",
    "    with ZipFile(filepath, 'r') as file:\n",
    "        file.extractall(path=extract_dir)\n",
    "        filenames = file.namelist()\n",
    "    \n",
    "    return extract_dir, filenames\n",
    "\n",
    "def save_docx(extracted_dir, filenames, output_filename):\n",
    "    with ZipFile(output_filename, 'w') as docx:\n",
    "        for filename in filenames: \n",
    "            docx.write(os.path.join(extracted_dir, filename), filename)\n",
    "            \n",
    "def save_document_xml(extracted_dir, xml):\n",
    "    with open(os.path.join(extracted_dir,'word/document.xml'), 'wb') as f:\n",
    "        xmlstr = get_string_xmltree(xml)\n",
    "        f.write(xmlstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentences(filepath):\n",
    "    from jsonpath_rw import jsonpath, parse\n",
    "    json_data     = json.load(codecs.open(fetch_content_filepath, 'r', 'utf-8-sig'))\n",
    "    jsonpath_expr = parse('$..tokenized_sentences[*]')\n",
    "    matches       = jsonpath_expr.find(json_data)\n",
    "\n",
    "    tokenized_sentences = []\n",
    "    for match in matches:\n",
    "        tokenized_sentences.append(match.value)\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_text(x, y, w, h, text):\n",
    "    xml_element = '<w:p xmlns:w=\"http://schemas.openxmlformats.org/wordprocessingml/2006/main\" xmlns:aink=\"http://schemas.microsoft.com/office/drawing/2016/ink\" xmlns:am3d=\"http://schemas.microsoft.com/office/drawing/2017/model3d\" xmlns:cx=\"http://schemas.microsoft.com/office/drawing/2014/chartex\" xmlns:cx1=\"http://schemas.microsoft.com/office/drawing/2015/9/8/chartex\" xmlns:cx2=\"http://schemas.microsoft.com/office/drawing/2015/10/21/chartex\" xmlns:cx3=\"http://schemas.microsoft.com/office/drawing/2016/5/9/chartex\" xmlns:cx4=\"http://schemas.microsoft.com/office/drawing/2016/5/10/chartex\" xmlns:cx5=\"http://schemas.microsoft.com/office/drawing/2016/5/11/chartex\" xmlns:cx6=\"http://schemas.microsoft.com/office/drawing/2016/5/12/chartex\" xmlns:cx7=\"http://schemas.microsoft.com/office/drawing/2016/5/13/chartex\" xmlns:cx8=\"http://schemas.microsoft.com/office/drawing/2016/5/14/chartex\" xmlns:m=\"http://schemas.openxmlformats.org/officeDocument/2006/math\" xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\" xmlns:o=\"urn:schemas-microsoft-com:office:office\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\" xmlns:v=\"urn:schemas-microsoft-com:vml\" xmlns:w10=\"urn:schemas-microsoft-com:office:word\" xmlns:w14=\"http://schemas.microsoft.com/office/word/2010/wordml\" xmlns:w15=\"http://schemas.microsoft.com/office/word/2012/wordml\" xmlns:w16=\"http://schemas.microsoft.com/office/word/2018/wordml\" xmlns:w16cex=\"http://schemas.microsoft.com/office/word/2018/wordml/cex\" xmlns:w16cid=\"http://schemas.microsoft.com/office/word/2016/wordml/cid\" xmlns:w16se=\"http://schemas.microsoft.com/office/word/2015/wordml/symex\" xmlns:wne=\"http://schemas.microsoft.com/office/word/2006/wordml\" xmlns:wp=\"http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing\" xmlns:wp14=\"http://schemas.microsoft.com/office/word/2010/wordprocessingDrawing\" xmlns:wpc=\"http://schemas.microsoft.com/office/word/2010/wordprocessingCanvas\" xmlns:wpg=\"http://schemas.microsoft.com/office/word/2010/wordprocessingGroup\" xmlns:wpi=\"http://schemas.microsoft.com/office/word/2010/wordprocessingInk\" xmlns:wps=\"http://schemas.microsoft.com/office/word/2010/wordprocessingShape\" w14:paraId=\"4B2133C5\" w14:textId=\"548353EB\" w:rsidR=\"0025221C\" w:rsidRDefault=\"00720170\"><w:r><w:rPr><w:noProof /></w:rPr><mc:AlternateContent><mc:Choice Requires=\"wps\"><w:drawing><wp:anchor distT=\"0\" distB=\"0\" distL=\"114300\" distR=\"114300\" simplePos=\"0\" relativeHeight=\"251659264\" behindDoc=\"0\" locked=\"0\" layoutInCell=\"1\" allowOverlap=\"1\" wp14:anchorId=\"4D373A9B\" wp14:editId=\"021DFA22\"><wp:simplePos x=\"0\" y=\"0\" /><wp:positionH relativeFrom=\"page\"><wp:posOffset>%d</wp:posOffset></wp:positionH><wp:positionV relativeFrom=\"page\"><wp:posOffset>%d</wp:posOffset></wp:positionV><wp:extent cx=\"%d\" cy=\"%d\" /><wp:effectExtent l=\"0\" t=\"0\" r=\"0\" b=\"0\" /><wp:wrapNone /><wp:docPr id=\"2\" name=\"Text Box 2\" /><wp:cNvGraphicFramePr /><a:graphic xmlns:a=\"http://schemas.openxmlformats.org/drawingml/2006/main\"><a:graphicData uri=\"http://schemas.microsoft.com/office/word/2010/wordprocessingShape\"><wps:wsp><wps:cNvSpPr txBox=\"1\" /><wps:spPr><a:xfrm><a:off x=\"0\" y=\"0\" /><a:ext cx=\"%d\" cy=\"%d\" /></a:xfrm><a:prstGeom prst=\"rect\"><a:avLst /></a:prstGeom><a:noFill /><a:ln w=\"6350\"><a:noFill /></a:ln></wps:spPr><wps:txbx><w:txbxContent><w:p w14:paraId=\"01C6C9C7\" w14:textId=\"6420C7CF\" w:rsidR=\"00720170\" w:rsidRPr=\"00720170\" w:rsidRDefault=\"00720170\"><w:pPr><w:rPr><w:lang w:val=\"en-US\" /></w:rPr></w:pPr><w:r><w:rPr><w:lang w:val=\"en-US\" /></w:rPr><w:t>%s</w:t></w:r></w:p></w:txbxContent></wps:txbx><wps:bodyPr rot=\"0\" spcFirstLastPara=\"0\" vertOverflow=\"overflow\" horzOverflow=\"overflow\" vert=\"horz\" wrap=\"square\" lIns=\"0\" tIns=\"0\" rIns=\"0\" bIns=\"0\" numCol=\"1\" spcCol=\"0\" rtlCol=\"0\" fromWordArt=\"0\" anchor=\"t\" anchorCtr=\"0\" forceAA=\"0\" compatLnSpc=\"1\"><a:prstTxWarp prst=\"textNoShape\"><a:avLst /></a:prstTxWarp><a:noAutofit /></wps:bodyPr></wps:wsp></a:graphicData></a:graphic></wp:anchor></w:drawing></mc:Choice></mc:AlternateContent></w:r></w:p>' % (x, y, w, h, w, h, text)\n",
    "    return get_xml_tree(xml_element)\n",
    "\n",
    "def get_pixel_twips(pixels):\n",
    "    PIXEL_TO_TWIPS = 14.999903622654\n",
    "    return int(PIXEL_TO_TWIPS * pixels)\n",
    "    \n",
    "def pixel_to_twips(px, dpi=108):\n",
    "    INCH_TO_TWIPS  = 1440\n",
    "    px_to_inches   = 1.0 / float(dpi)\n",
    "    return int(px * px_to_inches * INCH_TO_TWIPS)\n",
    "\n",
    "def pixels_to_emu(px):\n",
    "    PIXEL_TO_EMU = 9525\n",
    "    return int(PIXEL_TO_EMU * px)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_dir, filenames = extract_docx(input_filepath, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document has (3) text tags, tokenized sentences (85)\n"
     ]
    }
   ],
   "source": [
    "document_xml             = get_xmltree(os.path.join(extracted_dir, 'word', 'document.xml'))\n",
    "ps                       = get_specific_tags(document_xml, 'p')\n",
    "body                     = get_specific_tags(document_xml, 'body')\n",
    "\n",
    "tokenized_sentences      = get_tokenized_sentences(fetch_content_filepath)\n",
    "print('document has (%d) text tags, tokenized sentences (%d)' % (len(ps), len(tokenized_sentences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Reportable\"\n",
    "text_height = 19\n",
    "text_left = 695\n",
    "text_top = 108\n",
    "text_width = 90\n",
    "\n",
    "t1 = get_anchor_text(pixels_to_emu(text_left), pixels_to_emu(text_top), pixels_to_emu(text_width), \\\n",
    "                     pixels_to_emu(text_height), text)\n",
    "\n",
    "t2 = get_anchor_text(1270, 1880446, 4038600, 419100, 'IN THE SUPREME COURT OF INDIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "body[0].remove(ps[0])\n",
    "\n",
    "\n",
    "body[0].insert(0, t1)\n",
    "body[0].insert(1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_document_xml(extracted_dir, document_xml)\n",
    "save_docx(extracted_dir, filenames, os.path.join(output_dir, translated_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('cv3': conda)",
   "language": "python",
   "name": "python35664bitcv3conda56b31b492c17456d86703f6408b0e697"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
